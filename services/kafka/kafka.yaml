# Kafka StatefulSet and Service
apiVersion: v1
kind: Service
metadata:
  name: kafka-service
  namespace: production
  labels:
    app: kafka
    environment: production
spec:
  type: ClusterIP
  clusterIP: None  # Headless service
  selector:
    app: kafka
  ports:
    - name: kafka
      port: 9092
      targetPort: 9092
    - name: kafka-internal
      port: 29092
      targetPort: 29092
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: kafka
  namespace: production
  labels:
    app: kafka
    environment: production
spec:
  serviceName: kafka-service
  replicas: 1
  podManagementPolicy: OrderedReady
  updateStrategy:
    type: RollingUpdate
  selector:
    matchLabels:
      app: kafka
  template:
    metadata:
      labels:
        app: kafka
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "9308"
    spec:
      # Node Selection
      nodeSelector:
        kubernetes.io/arch: arm64
      
      # Tolerations
      tolerations:
        - key: node-role
          operator: Equal
          value: app
          effect: NoSchedule
      
      containers:
        # Zookeeper Container
        - name: zookeeper
          image: confluentinc/cp-zookeeper:7.5.0
          ports:
            - containerPort: 2181
              name: zookeeper
          env:
            - name: ZOOKEEPER_CLIENT_PORT
              value: "2181"
            - name: ZOOKEEPER_TICK_TIME
              value: "2000"
            - name: ZOOKEEPER_SYNC_LIMIT
              value: "2"
            - name: ZOOKEEPER_INIT_LIMIT
              value: "5"
            - name: ZOOKEEPER_MAX_CLIENT_CNXNS
              value: "60"
            - name: ZOOKEEPER_AUTOPURGE_SNAP_RETAIN_COUNT
              value: "3"
            - name: ZOOKEEPER_AUTOPURGE_PURGE_INTERVAL
              value: "24"
          resources:
            requests:
              cpu: 100m
              memory: 256Mi
            limits:
              cpu: 200m
              memory: 512Mi
          volumeMounts:
            - name: zookeeper-data
              mountPath: /var/lib/zookeeper/data
            - name: zookeeper-logs
              mountPath: /var/lib/zookeeper/log
        
        # Kafka Container
        - name: kafka
          image: confluentinc/cp-kafka:7.5.0
          ports:
            - containerPort: 9092
              name: kafka
            - containerPort: 29092
              name: kafka-internal
          env:
            - name: KAFKA_BROKER_ID
              value: "1"
            - name: KAFKA_ZOOKEEPER_CONNECT
              value: "localhost:2181"
            - name: KAFKA_ADVERTISED_LISTENERS
              value: "PLAINTEXT://kafka-service.production.svc.cluster.local:9092,INTERNAL://localhost:29092"
            - name: KAFKA_LISTENER_SECURITY_PROTOCOL_MAP
              value: "PLAINTEXT:PLAINTEXT,INTERNAL:PLAINTEXT"
            - name: KAFKA_INTER_BROKER_LISTENER_NAME
              value: "INTERNAL"
            - name: KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR
              value: "1"
            - name: KAFKA_TRANSACTION_STATE_LOG_MIN_ISR
              value: "1"
            - name: KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR
              value: "1"
            - name: KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS
              value: "0"
            - name: KAFKA_AUTO_CREATE_TOPICS_ENABLE
              value: "true"
            - name: KAFKA_LOG_RETENTION_HOURS
              value: "168"  # 7 days
            - name: KAFKA_LOG_SEGMENT_BYTES
              value: "1073741824"  # 1GB
            - name: KAFKA_LOG_CLEANUP_POLICY
              value: "delete"
            - name: KAFKA_COMPRESSION_TYPE
              value: "gzip"
            - name: KAFKA_MAX_MESSAGE_BYTES
              value: "1000012"  # 1MB
            - name: KAFKA_REPLICA_FETCH_MAX_BYTES
              value: "1048576"  # 1MB
            - name: KAFKA_CONFLUENT_METRICS_ENABLE
              value: "false"
          resources:
            requests:
              cpu: 200m
              memory: 512Mi
            limits:
              cpu: 500m
              memory: 1Gi
          volumeMounts:
            - name: kafka-data
              mountPath: /var/lib/kafka/data
          livenessProbe:
            tcpSocket:
              port: 9092
            initialDelaySeconds: 60
            periodSeconds: 10
            timeoutSeconds: 5
            failureThreshold: 3
          readinessProbe:
            tcpSocket:
              port: 9092
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
            successThreshold: 1
            failureThreshold: 3
        
        # Kafka Exporter for Prometheus
        - name: kafka-exporter
          image: danielqsj/kafka-exporter:latest
          ports:
            - containerPort: 9308
              name: metrics
          args:
            - --kafka.server=localhost:9092
            - --web.listen-address=:9308
            - --web.telemetry-path=/metrics
          resources:
            requests:
              cpu: 50m
              memory: 64Mi
            limits:
              cpu: 100m
              memory: 128Mi
      
      # Security Context
      securityContext:
        fsGroup: 1000
        runAsNonRoot: true
        runAsUser: 1000
      
      # DNS Policy
      dnsPolicy: ClusterFirst
      
      # Restart Policy
      restartPolicy: Always
      
      # Termination Grace Period
      terminationGracePeriodSeconds: 60
  
  # Volume Claim Templates
  volumeClaimTemplates:
    - metadata:
        name: kafka-data
      spec:
        accessModes: ["ReadWriteOnce"]
        storageClassName: gp3
        resources:
          requests:
            storage: 10Gi
    - metadata:
        name: zookeeper-data
      spec:
        accessModes: ["ReadWriteOnce"]
        storageClassName: gp3
        resources:
          requests:
            storage: 5Gi
    - metadata:
        name: zookeeper-logs
      spec:
        accessModes: ["ReadWriteOnce"]
        storageClassName: gp3
        resources:
          requests:
            storage: 5Gi
---
# Kafka Topics Creation Job
apiVersion: batch/v1
kind: Job
metadata:
  name: kafka-topic-creation
  namespace: production
spec:
  template:
    spec:
      restartPolicy: OnFailure
      containers:
        - name: kafka-topics
          image: confluentinc/cp-kafka:7.5.0
          command:
            - sh
            - -c
            - |
              echo "Waiting for Kafka to be ready..."
              sleep 30
              
              echo "Creating product-events topic..."
              kafka-topics --create --if-not-exists \
                --bootstrap-server kafka-service.production.svc.cluster.local:9092 \
                --topic product-events \
                --partitions 3 \
                --replication-factor 1 \
                --config retention.hours=168 \
                --config compression.type=gzip
              
              echo "Creating order-events topic..."
              kafka-topics --create --if-not-exists \
                --bootstrap-server kafka-service.production.svc.cluster.local:9092 \
                --topic order-events \
                --partitions 3 \
                --replication-factor 1 \
                --config retention.hours=168 \
                --config compression.type=gzip
              
              echo "Listing all topics..."
              kafka-topics --list --bootstrap-server kafka-service.production.svc.cluster.local:9092        storageClassName: gp3
        resources:
          requests:
            storage: 20Gi
